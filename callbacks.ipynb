{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "from functools import partial\n",
    "import re\n",
    "\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from fastprogress.fastprogress import format_time\n",
    "\n",
    "from exp.nb_utils import listify, camel2snake\n",
    "from exp.nb_metrics import AvgLoss, AvgSmoothLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Callback():\n",
    "    _order = 0\n",
    "\n",
    "    def set_learner(self, learner): self.learner = learner\n",
    "\n",
    "    def __getattr__(self, k): return getattr(self.learner, k)\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        f = getattr(self, cb_name, None)\n",
    "        if f and f(): return True\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "\n",
    "\n",
    "class CancelTrainException(Exception): pass\n",
    "class CancelFitException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass\n",
    "class CancelValidException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.learner.cur_train_epoch_flt = 0.\n",
    "        self.learner.cur_train_iter = 0\n",
    "\n",
    "    def begin_train(self):\n",
    "        self.learner.cur_train_epoch = self.epoch\n",
    "        self.learner.pct_train = self.epoch / self.epochs\n",
    "        self.model.train()\n",
    "        self.learner.in_train = True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.learner.in_train = False\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.learner.cur_train_epoch_flt += 1./self.iters\n",
    "        self.learner.pct_train += 1./(self.iters*self.epochs)\n",
    "        self.learner.cur_train_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train):\n",
    "        self.metrics, self.in_train = listify(metrics), in_train\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_loss = 0.\n",
    "        self.count = 0\n",
    "        self.total_metrics = [0.] * len(self.metrics)\n",
    "\n",
    "    @property\n",
    "    def all_stats(self): return [self.total_loss.item()] + self.total_metrics\n",
    "\n",
    "    @property\n",
    "    def avg_stats(self): return [s / self.count for s in self.all_stats]\n",
    "\n",
    "    def __repr__(self):\n",
    "        if not self.count:\n",
    "            return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, learner):\n",
    "        bn = learner.xb.shape[0]\n",
    "        self.total_loss += learner.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.total_metrics[i] += m(learner.pred, learner.yb) * bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "\n",
    "    def begin_fit(self):\n",
    "        met_names = ['loss'] + [m.__name__ for m in self.train_stats.metrics]\n",
    "        names = ['epoch'] + [f'train_{n}' for n in met_names] + [\n",
    "            f'valid_{n}' for n in met_names] + ['time']\n",
    "        #Write headers of table\n",
    "        self.logger(names)\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.learner)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        stats = [str(self.epoch)]\n",
    "        for o in [self.train_stats, self.valid_stats]:\n",
    "            stats += [f'{v:.6f}' for v in o.avg_stats]\n",
    "        stats += [format_time(time.time() - self.start_time)]\n",
    "        #Write row\n",
    "        self.logger(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Recorder1(Callback):\n",
    "    def begin_fit(self): self.lrs, self.losses = [], []\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
    "        self.losses.append(self.loss.detach().cpu())\n",
    "\n",
    "    def plot_lr(self): plt.plot(self.lrs)\n",
    "\n",
    "    def plot_loss(self): plt.plot(self.losses)\n",
    "\n",
    "    def plot(self, skip_last=0):\n",
    "        losses = [o.item() for o in self.losses]\n",
    "        n = len(losses)-skip_last\n",
    "        plt.xscale('log')\n",
    "        plt.plot(self.lrs[:n], losses[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Recorder(Callback):\n",
    "    _order = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def _maybe_item(t):\n",
    "        t = t.value\n",
    "        return t.item() if isinstance(t, Tensor) and t.numel() == 1 else t\n",
    "\n",
    "    def __init__(self, beta=0.98):\n",
    "        self.loss = AvgLoss()\n",
    "        self.smooth_loss = AvgSmoothLoss(beta=beta)\n",
    "\n",
    "    def begin_fit(self):\n",
    "        self.lrs, self.iters, self.losses, self.values = [], [], [], []\n",
    "        headers = [\"loss\"] + [m.name for m in self.metrics]\n",
    "        train_h = [\"train_{}\".format(h) for h in headers]\n",
    "        valid_h = [\"valid_{}\".format(h) for h in headers]\n",
    "        headers = [\"epoch\"] + train_h + valid_h\n",
    "        headers.append(\"time\")\n",
    "        self.metric_names = headers\n",
    "        self.smooth_loss.reset()\n",
    "#         self.logger(self.metric_names)\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.cancel_train, self.cancel_valid = False, False\n",
    "        self.start_epoch = time.time()\n",
    "        self.log = [getattr(self, 'epoch', 0)]\n",
    "\n",
    "    def begin_train(self):\n",
    "        # Reset except smooth_loss\n",
    "        for m in self._train_mets[1:]:\n",
    "            m.reset()\n",
    "\n",
    "    def begin_validate(self):\n",
    "        for m in self._valid_mets:\n",
    "            m.reset()\n",
    "\n",
    "    def after_train(self):\n",
    "        self.log += map(lambda x: self._maybe_item(x), self._train_mets)\n",
    "\n",
    "    def after_validate(self):\n",
    "        self.log += map(lambda x: self._maybe_item(x), self._valid_mets)\n",
    "\n",
    "    def after_cancel_train(self):\n",
    "        self.cancel_train = True\n",
    "\n",
    "    def after_cancel_validate(self):\n",
    "        self.cancel_validate = True\n",
    "\n",
    "    def after_epoch(self):\n",
    "        self.learner.final_record = self.log[1:].copy()\n",
    "        self.values.append(self.learner.final_record)\n",
    "\n",
    "        self.log.append(format_time(time.time() - self.start_epoch))\n",
    "        self.logger(self.log)\n",
    "        self.iters.append(self.smooth_loss.count)\n",
    "\n",
    "    def after_batch(self):\n",
    "        if len(self.yb) == 0: return\n",
    "        mets = self._train_mets if self.in_train else self._valid_mets\n",
    "        for met in mets: met.accumulate(self.learner)\n",
    "        if not self.in_train: return\n",
    "        self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
    "        self.losses.append(self.smooth_loss.value)\n",
    "        self.learner.smooth_loss = self.smooth_loss.value\n",
    "\n",
    "    def plot_loss(self, skip_start=5, with_valid=True):\n",
    "        plt.plot(list(range(skip_start, len(self.losses))), self.losses[skip_start:], label='train')\n",
    "        if with_valid:\n",
    "            idx = (np.array(self.iters) < skip_start).sum()\n",
    "            plt.plot(self.iters[idx:], self.values[idx:], label='valid')\n",
    "            plt.legend()\n",
    "\n",
    "    @property\n",
    "    def _train_mets(self):\n",
    "        if getattr(self, 'cancel_train', False): return []\n",
    "        return [self.smooth_loss] + self.metrics\n",
    "\n",
    "    @property\n",
    "    def _valid_mets(self):\n",
    "        return [self.loss] + self.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamScheduler(Callback):\n",
    "    _order = 1\n",
    "\n",
    "    def __init__(self, pname, sched_funcs):\n",
    "        self.pname,self.sched_funcs = pname,listify(sched_funcs)\n",
    "\n",
    "    def begin_batch(self):\n",
    "        if not self.in_train: return\n",
    "        fs = self.sched_funcs\n",
    "        if len(fs)==1: fs = fs*len(self.opt.param_groups)\n",
    "        pos = self.cur_train_epoch_flt/self.epochs\n",
    "        for f,h in zip(fs,self.opt.param_groups): h[self.pname] = f(pos)\n",
    "\n",
    "\n",
    "class LR_Find(Callback):\n",
    "    _order = 1\n",
    "\n",
    "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
    "        self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr\n",
    "        self.best_loss = 1e9\n",
    "\n",
    "    def begin_batch(self):\n",
    "        if not self.in_train: return\n",
    "        pos = self.iter/self.max_iter\n",
    "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos\n",
    "        for pg in self.opt.param_groups: pg['lr'] = lr\n",
    "\n",
    "    def after_step(self):\n",
    "        if self.iter>=self.max_iter or self.loss>self.best_loss*10:\n",
    "            raise CancelTrainException()\n",
    "        if self.loss < self.best_loss: self.best_loss = self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgressCallback1(Callback):\n",
    "    _order = -1\n",
    "\n",
    "    def begin_fit(self):\n",
    "        self.mbar = master_bar(range(self.epochs))\n",
    "#         self.mbar.on_iter_begin()\n",
    "        self.learner.set_logger(partial(self.mbar.write, table=True))\n",
    "\n",
    "    def after_fit(self): self.mbar.on_iter_end()\n",
    "    def after_batch(self): self.pb.update(self.iter)\n",
    "    def begin_epoch(self): self.set_pb()\n",
    "    def begin_validate(self): self.set_pb()\n",
    "\n",
    "    def set_pb(self):\n",
    "        self.pb = progress_bar(self.dl, parent=self.mbar)\n",
    "        self.mbar.update(self.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProgressCallback(Callback):\n",
    "    _order = 1\n",
    "\n",
    "    def begin_fit(self):\n",
    "        assert hasattr(self.learner, 'recorder')\n",
    "        self.mbar = master_bar(list(range(self.epochs)))\n",
    "        self._write_stats(self.recorder.metric_names)\n",
    "        self.learner.logger = self._write_stats\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        if getattr(self, 'mbar', None): self.mbar.update(self.epoch)\n",
    "\n",
    "    def begin_train(self):\n",
    "        self._launch_pbar()\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self._launch_pbar()\n",
    "\n",
    "    def after_train(self):\n",
    "        self.pbar.on_iter_end()\n",
    "\n",
    "    def after_validate(self):\n",
    "        self.pbar.on_iter_end()\n",
    "\n",
    "    def after_batch(self):\n",
    "        self.pbar.update(self.iter + 1)\n",
    "        if hasattr(self, 'smooth_loss'):\n",
    "            self.pbar.comment = f\"{self.smooth_loss:.4f}\"\n",
    "\n",
    "    def after_fit(self):\n",
    "        if getattr(self, 'mbar', None):\n",
    "            self.mbar.on_iter_end()\n",
    "            delattr(self, 'mbar')\n",
    "        self.learner.logger = print\n",
    "\n",
    "    def _write_stats(self, log):\n",
    "        if getattr(self, 'mbar', None):\n",
    "            self.mbar.write([f\"{l:.6f}\" if isinstance(l, float) else str(l) for l in log], table=True)\n",
    "\n",
    "    def _launch_pbar(self):\n",
    "        self.pbar = progress_bar(self.dl, parent=getattr(self, 'mbar', None), leave=False)\n",
    "        self.pbar.update(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CudaCallback(Callback):\n",
    "    _order = -1\n",
    "    def begin_fit(self): self.model.cuda()\n",
    "    def begin_batch(self): self.learner.xb,self.learner.yb = self.xb.cuda(),self.yb.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted callbacks.ipynb to exp/nb_callbacks.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py callbacks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

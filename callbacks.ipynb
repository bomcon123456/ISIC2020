{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from fastprogress.fastprogress import format_time\n",
    "\n",
    "from exp.nb_utils import listify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import re\n",
    "\n",
    "_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n",
    "_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n",
    "\n",
    "\n",
    "def camel2snake(name):\n",
    "    s1 = re.sub(_camel_re1, r'\\1_\\2', name)\n",
    "    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()\n",
    "\n",
    "\n",
    "class Callback():\n",
    "    _order = 0\n",
    "\n",
    "    def set_learner(self, learner): self.learner = learner\n",
    "\n",
    "    def __getattr__(self, k): return getattr(self.learner, k)\n",
    "\n",
    "    def __call__(self, cb_name):\n",
    "        f = getattr(self, cb_name, None)\n",
    "        if f and f(): return True\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        name = re.sub(r'Callback$', '', self.__class__.__name__)\n",
    "        return camel2snake(name or 'callback')\n",
    "\n",
    "\n",
    "class CancelTrainException(Exception): pass\n",
    "class CancelEpochException(Exception): pass\n",
    "class CancelBatchException(Exception): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class TrainEvalCallback(Callback):\n",
    "    def begin_fit(self):\n",
    "        self.learner.cur_train_epoch_flt = 0.\n",
    "        self.learner.cur_train_iter = 0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.learner.cur_train_epoch = self.epoch\n",
    "        self.model.train()\n",
    "        self.learner.in_train = True\n",
    "\n",
    "    def begin_validate(self):\n",
    "        self.model.eval()\n",
    "        self.learner.in_train = False\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.learner.cur_train_epoch_flt += 1./self.iters\n",
    "        self.learner.cur_train_iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgStats():\n",
    "    def __init__(self, metrics, in_train):\n",
    "        self.metrics, self.in_train = listify(metrics), in_train\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.total_loss = 0.\n",
    "        self.count = 0\n",
    "        self.total_metrics = [0.] * len(self.metrics)\n",
    "\n",
    "    @property\n",
    "    def all_stats(self): return [self.total_loss.item()] + self.total_metrics\n",
    "\n",
    "    @property\n",
    "    def avg_stats(self): return [s / self.count for s in self.all_stats]\n",
    "\n",
    "    def __repr__(self):\n",
    "        if not self.count:\n",
    "            return \"\"\n",
    "        return f\"{'train' if self.in_train else 'valid'}: {self.avg_stats}\"\n",
    "\n",
    "    def accumulate(self, learner):\n",
    "        bn = learner.xb.shape[0]\n",
    "        self.total_loss += learner.loss * bn\n",
    "        self.count += bn\n",
    "        for i,m in enumerate(self.metrics):\n",
    "            self.total_metrics[i] += m(learner.pred, learner.yb) * bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AvgStatsCallback(Callback):\n",
    "    def __init__(self, metrics):\n",
    "        self.train_stats,self.valid_stats = AvgStats(metrics,True),AvgStats(metrics,False)\n",
    "\n",
    "    def begin_fit(self):\n",
    "        met_names = ['loss'] + [m.__name__ for m in self.train_stats.metrics]\n",
    "        names = ['epoch'] + [f'train_{n}' for n in met_names] + [\n",
    "            f'valid_{n}' for n in met_names] + ['time']\n",
    "        #Write headers of table\n",
    "        self.logger(names)\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.train_stats.reset()\n",
    "        self.valid_stats.reset()\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def after_loss(self):\n",
    "        stats = self.train_stats if self.in_train else self.valid_stats\n",
    "        with torch.no_grad(): stats.accumulate(self.learner)\n",
    "\n",
    "    def after_epoch(self):\n",
    "        stats = [str(self.epoch)]\n",
    "        for o in [self.train_stats, self.valid_stats]:\n",
    "            stats += [f'{v:.6f}' for v in o.avg_stats]\n",
    "        stats += [format_time(time.time() - self.start_time)]\n",
    "        #Write row\n",
    "        self.logger(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Recorder(Callback):\n",
    "    def begin_fit(self): self.lrs, self.losses = [], []\n",
    "\n",
    "    def after_batch(self):\n",
    "        if not self.in_train: return\n",
    "        self.lrs.append(self.opt.param_groups[-1]['lr'])\n",
    "        self.losses.append(self.loss.detach().cpu())\n",
    "\n",
    "    def plot_lr(self): plt.plot(self.lrs)\n",
    "\n",
    "    def plot_loss(self): plt.plot(self.losses)\n",
    "\n",
    "    def plot(self, skip_last=0):\n",
    "        losses = [o.item() for o in self.losses]\n",
    "        n = len(losses)-skip_last\n",
    "        plt.xscale('log')\n",
    "        plt.plot(self.lrs[:n], losses[:n])\n",
    "\n",
    "\n",
    "class ParamScheduler(Callback):\n",
    "    _order = 1\n",
    "\n",
    "    def __init__(self, pname, sched_funcs):\n",
    "        self.pname,self.sched_funcs = pname,listify(sched_funcs)\n",
    "\n",
    "    def begin_batch(self):\n",
    "        if not self.in_train: return\n",
    "        fs = self.sched_funcs\n",
    "        if len(fs)==1: fs = fs*len(self.opt.param_groups)\n",
    "        pos = self.cur_train_epoch_flt/self.epochs\n",
    "        for f,h in zip(fs,self.opt.param_groups): h[self.pname] = f(pos)\n",
    "\n",
    "\n",
    "class LR_Find(Callback):\n",
    "    _order = 1\n",
    "\n",
    "    def __init__(self, max_iter=100, min_lr=1e-6, max_lr=10):\n",
    "        self.max_iter,self.min_lr,self.max_lr = max_iter,min_lr,max_lr\n",
    "        self.best_loss = 1e9\n",
    "\n",
    "    def begin_batch(self):\n",
    "        if not self.in_train: return\n",
    "        pos = self.cur_train_iter/self.max_iter\n",
    "        lr = self.min_lr * (self.max_lr/self.min_lr) ** pos\n",
    "        for pg in self.opt.param_groups: pg['lr'] = lr\n",
    "\n",
    "    def after_step(self):\n",
    "        if self.iter>=self.max_iter or self.loss>self.best_loss*10:\n",
    "            raise CancelTrainException()\n",
    "        if self.loss < self.best_loss: self.best_loss = self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ProgressCallback(Callback):\n",
    "    _order = -1\n",
    "\n",
    "    def begin_fit(self):\n",
    "        self.mbar = master_bar(range(self.epochs))\n",
    "#         self.mbar.on_iter_begin()\n",
    "        self.learner.set_logger(partial(self.mbar.write, table=True))\n",
    "\n",
    "    def after_fit(self): self.mbar.on_iter_end()\n",
    "    def after_batch(self): self.pb.update(self.iter)\n",
    "    def begin_epoch   (self): self.set_pb()\n",
    "    def begin_validate(self): self.set_pb()\n",
    "\n",
    "    def set_pb(self):\n",
    "        self.pb = progress_bar(self.dl, parent=self.mbar)\n",
    "        self.mbar.update(self.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CudaCallback(Callback):\n",
    "    def begin_fit(self): self.model.cuda()\n",
    "    def begin_batch(self): self.run.xb,self.run.yb = self.xb.cuda(),self.yb.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted callbacks.ipynb to exp\\nb_callbacks.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py callbacks.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
